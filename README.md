# Voice Flow üé§‚ú®

> A sophisticated voice-enabled AI assistant with enterprise-grade analytics, privacy controls, and multi-model support.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![JavaScript](https://img.shields.io/badge/JavaScript-ES2022-yellow.svg)](https://developer.mozilla.org/en-US/docs/Web/JavaScript)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

## ‚ú® What Makes Voice Flow Special

Voice Flow is a **production-ready AI assistant** that seamlessly combines voice and text interaction with enterprise-level features you won't find elsewhere:

- üéØ **Intelligent Conversation Management** - Smart memory pruning keeps conversations flowing naturally
- üìä **Advanced Analytics Dashboard** - Deep insights into usage patterns and performance metrics  
- üîê **Privacy-First Architecture** - GDPR-compliant logging with user consent and data sanitization
- üé® **Professional UI/UX** - Responsive design with smooth animations and accessibility features
- ‚ö° **Real-time Performance Monitoring** - Live metrics for STT, LLM, and TTS processing
- üõ°Ô∏è **Enterprise-Grade Error Handling** - Automatic retry, graceful degradation, and smart recovery
- üîí **HTTPS Support** - Full HTTPS compatibility for secure deployments and mobile browser support

## üì∏ Screenshots

### Main Interface
![Voice Flow Main Interface](screenshots/main-interface.png)
*Clean, modern chat interface with real-time conversation management and performance monitoring*

### Comprehensive Settings System

#### Model Configuration
![Model Settings](screenshots/settings-model.png)
*Dynamic model selection with automatic detection of installed Ollama models and parameter tuning*

#### Audio & Voice Settings  
![Audio Settings](screenshots/settings-audio.png)
*Professional audio controls with 14 voice options, speech rate adjustment, and volume controls*

#### Appearance & Themes
![Appearance Settings](screenshots/settings-appearance.png)
*Multiple theme options with smooth transitions and accessibility features*

#### Logging & Analytics
![Logging Settings](screenshots/settings-logging.png)
*Enterprise-grade logging with privacy controls, data export, and analytics configuration*

---

## üöÄ Quick Start

### Prerequisites

You'll need these services running:

1. **[Ollama](https://ollama.ai/)** - Local LLM service (required)
2. **[Kokoro TTS](https://github.com/remsky/Kokoro-FastAPI)** - Text-to-speech (optional)
3. **[Whisper STT](https://github.com/ahmetoner/whisper-asr-webservice)** - Speech-to-text (optional)

### Installation

#### Option 1: HTTP Mode (Development)

Perfect for local development and testing.

```bash
# Clone the repository
git clone https://github.com/johnriggs1959/voice-flow.git
cd voice-flow

# Start Voice Flow
python3 -m http.server 8020

# Open your browser
# http://localhost:8020
```

#### Option 2: HTTPS Mode (Production/Mobile)

Required for mobile browsers and production deployments.

```bash
# 1. Setup Nginx (see HTTPS Setup section below)
# 2. Start Voice Flow via Nginx
# 3. Open your browser
# https://localhost
```

The app automatically detects your protocol and configures itself accordingly!

## üéØ Key Features

### ü§ñ AI Integration

* **Multi-Model Support** - Automatically detects all installed Ollama models
* **Dynamic Model Switching** - Change models without restarting
* **Intelligent Responses** - Voice-optimized AI responses with natural speech formatting
* **Smart Context Management** - Maintains conversation context with memory optimization
* **HTTPS Configuration** - Dynamic service URL configuration for both HTTP and HTTPS modes

### üéôÔ∏è Voice & Audio

* **High-Quality Speech Recognition** - Powered by OpenAI Whisper
* **Natural Text-to-Speech** - 14 voice options (American & British English)
* **Hands-Free Operation** - Voice ‚Üí Transcription ‚Üí AI Response ‚Üí Speech
* **Professional Audio Controls** - Play, pause, download generated speech
* **Mobile Browser Support** - Full voice functionality on mobile via HTTPS

### üìä Analytics & Monitoring

* **Real-Time Performance Metrics** - Track STT, LLM, and TTS processing times
* **Usage Pattern Analysis** - Peak hours, preferred models, conversation insights
* **Service Health Monitoring** - Live status indicators for all connected services
* **Export Capabilities** - Download logs in JSON, CSV, or Markdown format

### üîê Privacy & Security

* **User Consent Management** - GDPR-compliant privacy controls
* **Data Sanitization** - Automatic filtering of sensitive information
* **Local-First Architecture** - Your data stays on your devices
* **Configurable Retention** - Automatic cleanup of old conversation logs
* **HTTPS Support** - Secure communication for production deployments

### üé® User Experience

* **Responsive Design** - Works beautifully on desktop, tablet, and mobile
* **Theme System** - Light, dark, and custom themes with smooth transitions
* **Accessibility First** - Screen reader support, keyboard navigation, WCAG compliant
* **Touch-Friendly** - Optimized for mobile voice interaction
* **Configuration Manager** - Easy setup for HTTP and HTTPS modes

## üìñ Setup Guide

### 1. Ollama Setup (Required)

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull some models
ollama pull llama3.2:3b      # Fast, balanced (recommended)
ollama pull llama3.1:8b      # Higher quality
ollama pull tinyllama:1.1b   # Ultra-fast

# Configure for network access
export OLLAMA_HOST=0.0.0.0:11434
export OLLAMA_ORIGINS=*

# Or configure systemd service
sudo systemctl edit ollama
```

Add this configuration:
```ini
[Service]
Environment="OLLAMA_HOST=0.0.0.0:11434"
Environment="OLLAMA_ORIGINS=*"
```

```bash
# Restart service
sudo systemctl restart ollama
```

### 2. Kokoro TTS Setup (Optional)

```bash
# Clone and start TTS service
git clone https://github.com/remsky/Kokoro-FastAPI.git
cd Kokoro-FastAPI
docker-compose up -d

#OR
docker run -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-cpu:v0.1.4 # CPU, or:
docker run --gpus all -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-gpu:v0.1.4 #NVIDIA GPU
```

### 3. Whisper STT Setup (Optional)

```bash
# Start Whisper service
docker run -d \
  --name whisper-api \
  -p 8000:8000 \
  -e ASR_MODEL=base \
  onerahmet/openai-whisper-asr-webservice:latest
```

## üîí HTTPS Setup (For Production/Mobile)

### Step 1: Install Nginx

```bash
# Ubuntu/Debian
sudo apt install nginx

# macOS
brew install nginx
```

### Step 2: Generate SSL Certificate

```bash
# Self-signed certificate (for testing)
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout /etc/ssl/private/localhost.key \
  -out /etc/ssl/certs/localhost.crt \
  -subj "/CN=localhost"

# For production, use Let's Encrypt
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d yourdomain.com
```

### Step 3: Configure Nginx

Create `/etc/nginx/sites-available/voice-flow`:

```nginx
server {
    listen 443 ssl http2;
    server_name localhost;
    
    ssl_certificate /etc/ssl/certs/localhost.crt;
    ssl_certificate_key /etc/ssl/private/localhost.key;
    
    # Voice Flow app files
    root /var/www/voice-flow;
    index index.html;
    
    location / {
        try_files $uri $uri/ /index.html;
    }
    
    # Proxy to Ollama
    location /ollama/ {
        proxy_pass http://localhost:11434/;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_buffering off;
        add_header Access-Control-Allow-Origin *;
    }
    
    # Proxy to TTS
    location /tts/ {
        proxy_pass http://localhost:8880/;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_buffering off;
        add_header Access-Control-Allow-Origin *;
    }
    
    # Proxy to STT
    location /stt/ {
        proxy_pass http://localhost:8000/;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_buffering off;
        client_max_body_size 10M;
        add_header Access-Control-Allow-Origin *;
    }
}
```

### Step 4: Setup Voice Flow for Nginx

```bash
# Copy Voice Flow to Nginx directory
sudo cp -r /path/to/voice-flow /var/www/
sudo chown -R www-data:www-data /var/www/voice-flow

# Or use a symbolic link for development
sudo ln -s /path/to/voice-flow /var/www/voice-flow
chmod 755 ~/voice-flow-directory
sudo usermod -a -G $USER www-data
```

### Step 5: Enable and Start

```bash
# Enable the site
sudo ln -s /etc/nginx/sites-available/voice-flow /etc/nginx/sites-enabled/

# Test configuration
sudo nginx -t

# Restart Nginx
sudo systemctl restart nginx
```

## üîß Configuration

### Using the Configuration Manager

1. Open `config.html` in your browser
2. The app auto-detects HTTP or HTTPS mode
3. Test each service connection
4. Save configuration

The configuration automatically adjusts based on your protocol:

- **HTTP Mode:**
  - Ollama: `http://localhost:11434`
  - TTS: `http://localhost:8880`
  - STT: `http://localhost:8000`

- **HTTPS Mode (via Nginx):**
  - Ollama: `https://localhost/ollama`
  - TTS: `https://localhost/tts`
  - STT: `https://localhost/stt`

## üéµ Usage Examples

### Voice Interaction
1. Click the microphone button
2. Ask your question naturally
3. Watch as it transcribes, processes, and responds with voice

### Model Selection
* **tinyllama:1.1b** - Lightning fast for simple questions
* **llama3.2:3b** - Perfect balance of speed and quality
* **llama3.1:8b** - Detailed, thoughtful responses
* **Custom models** - Add any Ollama-compatible model

### Mobile Access
For mobile browsers, HTTPS is required:
1. Setup HTTPS with Nginx (see above)
2. Find your computer's IP: `ip addr | grep inet`
3. Access from mobile: `https://your-ip-address`

## üèóÔ∏è Architecture

Voice Flow is built with a modular, enterprise-grade architecture:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   UI Layer      ‚îÇ  ‚îÇ  Service Layer  ‚îÇ  ‚îÇ  Data Layer     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Chat Interface‚îÇ  ‚îÇ ‚Ä¢ API Service   ‚îÇ  ‚îÇ ‚Ä¢ Conversation  ‚îÇ
‚îÇ ‚Ä¢ Settings      ‚îÇ  ‚îÇ ‚Ä¢ Audio Service ‚îÇ  ‚îÇ ‚Ä¢ Analytics     ‚îÇ
‚îÇ ‚Ä¢ Themes        ‚îÇ  ‚îÇ ‚Ä¢ Model Mgmt    ‚îÇ  ‚îÇ ‚Ä¢ Logging       ‚îÇ
‚îÇ ‚Ä¢ Status        ‚îÇ  ‚îÇ ‚Ä¢ Error Handling‚îÇ  ‚îÇ ‚Ä¢ Privacy       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Design Principles
* **Memory Efficient** - Smart conversation pruning prevents memory leaks
* **Error Resilient** - Comprehensive error handling with automatic recovery
* **Privacy Conscious** - User consent and data protection built-in
* **Performance Focused** - Real-time monitoring and optimization
* **Protocol Agnostic** - Automatic configuration for HTTP/HTTPS

## üìä Performance

* **Response Time** < 3s average (STT + LLM + TTS)
* **Memory Usage** < 50MB with automatic pruning
* **Error Rate** < 2% with automatic retry
* **Accessibility** WCAG 2.1 AA compliant
* **Browser Support** All modern browsers

## üêõ Troubleshooting

### Service Connection Issues

```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Check TTS service
curl http://localhost:8880/v1/test

# Check STT service
curl http://localhost:8000/v1/test

# For HTTPS, test through Nginx
curl -k https://localhost/ollama/api/tags
curl -k https://localhost/tts/v1/test
curl -k https://localhost/stt/v1/test
```

### HTTPS Certificate Issues
* **Browser shows "Not Secure"**: Normal for self-signed certificates. Click "Advanced" ‚Üí "Proceed"
* **For production**: Use Let's Encrypt for trusted certificates

### Voice Input Issues
* **On mobile**: Ensure you're using HTTPS (required for getUserMedia API)
* Check browser microphone permissions
* Verify microphone is working in other apps

### Nginx Permission Issues
```bash
# If you see permission denied errors
sudo chown -R www-data:www-data /var/www/voice-flow
# Or use symbolic link method (see HTTPS Setup)
```

## üõ£Ô∏è Roadmap

### üéØ Phase 1: Enhanced UX (Next)
* Voice command navigation
* Advanced model management interface
* Conversation search and filtering
* Custom wake words

### üìä Phase 2: Intelligence
* Predictive analytics dashboard
* AI-powered usage insights
* Performance optimization suggestions
* Smart conversation summarization

### üè¢ Phase 3: Enterprise
* Multi-user support with profiles
* API integrations and webhooks
* Plugin system for extensibility
* Advanced security features

## ü§ù Contributing

We love contributions! Here's how to get started:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and test thoroughly
4. Commit with clear messages: `git commit -m 'Add amazing feature'`
5. Push to your branch: `git push origin feature/amazing-feature`
6. Open a Pull Request

### Development Setup

```bash
# Fork and clone your fork
git clone https://github.com/yourusername/voice-flow.git
cd voice-flow

# For HTTP development
python3 -m http.server 8020

# For HTTPS testing
# Follow the HTTPS Setup section above
```

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

* [Ollama](https://ollama.ai/) for excellent local LLM runtime
* [Kokoro TTS](https://github.com/remsky/Kokoro-FastAPI) for high-quality speech synthesis
* [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition
* The open-source AI community for inspiration and tools

## üìû Support

* üìö [Documentation](https://github.com/johnriggs1959/voice-flow/wiki) (coming soon)
* üêõ [Issue Tracker](https://github.com/johnriggs1959/voice-flow/issues)
* üí¨ [Discussions](https://github.com/johnriggs1959/voice-flow/discussions)

---

‚≠ê **Star this repository if it helped you!** ‚≠ê

Made with ‚ù§Ô∏è by [John Riggs](https://github.com/johnriggs1959)
